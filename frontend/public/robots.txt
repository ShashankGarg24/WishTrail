# robots.txt for WishTrail
# Goal tracking platform - https://wishtrail.in
# Last updated: 2025-12-25

# Default rules for all crawlers
User-agent: *

# Public pages - Allow indexing
Allow: /
Allow: /auth
Allow: /inspiration

# Legal pages - Allow for transparency
Allow: /privacy-policy
Allow: /terms-of-service
Allow: /community-guidelines
Allow: /copyright-policy

# User-specific pages - Block from indexing
Disallow: /dashboard
Disallow: /profile/*/settings
Disallow: /notifications
Disallow: /settings
Disallow: /reset-password

# API endpoints - Block all bots
Disallow: /api/

# Static assets - Allow but with low priority
Allow: /assets/
Allow: /*.css$
Allow: /*.js$
Allow: /*.png$
Allow: /*.jpg$
Allow: /*.svg$
Allow: /*.webp$

# Social feed - Allow but deprioritize (dynamic content)
Allow: /feed

# Sitemap location
Sitemap: https://wishtrail.in/sitemap.xml

# Google-specific optimizations
User-agent: Googlebot
Allow: /
Crawl-delay: 0.5

User-agent: Googlebot-Image
Allow: /

# Bing optimizations
User-agent: Bingbot
Allow: /
Crawl-delay: 0.5

# Yahoo/Verizon Media
User-agent: Slurp
Allow: /
Crawl-delay: 1

# DuckDuckGo
User-agent: DuckDuckBot
Allow: /
Crawl-delay: 1

# Block bad bots
User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: DotBot
Disallow: /

# Block AI scrapers (optional - uncomment if needed)
# User-agent: GPTBot
# Disallow: /
#
# User-agent: CCBot
# Disallow: /
#
# User-agent: anthropic-ai
# Disallow: /

# General crawl rate
Crawl-delay: 1